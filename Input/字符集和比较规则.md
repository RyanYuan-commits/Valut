---
source:
type: input
banner: Assets/Banner/pexels-8kspain-21564213.jpg
---
# 📰 阅读笔记

- 字符集: 一个系统支持的所有抽象字符的集合, 它规定了有哪些字符，并给每个字符分配一个唯一的数字编号(称为码点), 例如，"A"的码点是65，"汉"的码点是27721, 
	
- 字符编码: 将字符集中的码点转换为计算机中实际存储的二进制字节(以及反向转换)的规则, 同一个字符集可以有多种编码方式, 

ASCII 是最早也是最基础的字符编码, 它用一个字节中的 7 位二进制数来表示 128 个字符, 包括英文字母, 数字和常用符号. 由于其设计初衷是为了服务英语环境, 它无法表示其他语言的文字, 是计算机字符处理的起点, 但其局限性也催生了后续各种扩展编码的出现.

ISO-8859-1 (Latin-1) 是为了弥补ASCII的不足而生的, 它充分利用了一个字节的8位, 将编码范围扩展到256个字符. 它的前 128 位与 ASCII 完全一致, 保证了兼容性, 后 128 位则用来表示西欧语言中的特殊字母和符号. 然而, 它单字节的限制决定了它依然无法处理像中文这样需要大量字符的书写系统.

为了解决中文编码问题, 中国制定了 GB2312 及其扩展 GBK 这一系列国家标准. 它们采用巧妙的变长编码方案: 对于原有的ASCII字符, 仍用单字节表示以保持兼容; 对于数以万计的汉字, 则用两个字节来表示. GBK 向下兼容GB2312, 并收录了更多汉字和符号, 曾在中文 Windows 系统中被广泛使用, 但其本质是一种区域性的解决方案.

最终, 为了统一全球所有字符的表示, Unicode (万国码) 应运而生. 它不是一个具体的编码规则, 而是一个宏大的字符集, 为全世界的每一个字符分配一个唯一的数字编号(称为“码点”). 而如何将这个庞大的码点序列转换成二进制字节进行存储和传输, 则由具体的编码方案来实现, 其中最核心的就是 UTF-8.

UTF-8 是 Unicode 最成功和普及的编码实现, 它采用智能的变长编码(1 到 4 个字节), 其最大优点是完美兼容 ASCII 码, 并且没有字节序的困扰, 这使得它在处理英文时极其高效, 同时又能容纳所有语言字符. 正因如此, UTF-8 已成为互联网网页, 现代操作系统和软件开发中字符编码的绝对主流和首选标准.

除了 UTF-8, Unicode 还有其他编码方案, 例如 UTF-16, 它通常使用两个或四个字节来表示一个字符, 是 Java 和 Windows 系统内部常用的编码方式, 但它不兼容 ASCII 且存在字节序问题; 以及 UTF-32, 它简单粗暴地用四个字节固定表示每个字符, 便于处理但非常浪费空间,通常仅限于内部计算, 很少用于实际存储和传输. 



---

# 💭 我的思考

这个观点如何与我已知的知识产生联系? 它让我想到了什么?